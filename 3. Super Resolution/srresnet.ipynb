{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport os\n\nplt.rcParams[\"figure.figsize\"] = (7, 7)","metadata":{"executionInfo":{"elapsed":351,"status":"ok","timestamp":1643738729076,"user":{"displayName":"Ashmit Khandelwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKpmFtCMTisPramwd0ZvJzP7b04l1R2eRcTeut0g=s64","userId":"09685033332413984276"},"user_tz":-330},"id":"2s-cuvvWOPn-","execution":{"iopub.status.busy":"2022-02-17T18:58:17.482941Z","iopub.execute_input":"2022-02-17T18:58:17.483464Z","iopub.status.idle":"2022-02-17T18:58:21.553268Z","shell.execute_reply.started":"2022-02-17T18:58:17.483422Z","shell.execute_reply":"2022-02-17T18:58:21.552529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define tensorflow pipeline","metadata":{}},{"cell_type":"code","source":"def load_img(file):\n    # load and process the image\n    img = tf.io.read_file(file)\n    img = tf.io.decode_jpeg(img)\n    img = tf.image.convert_image_dtype(img, tf.float32)\n\n    return img\n\n# unused, for now\ndef upsample(img, size):\n    # upscale using bicubic interpolation\n    img = tf.image.resize(\n        img,\n        (size, size),\n        method=tf.image.ResizeMethod.BICUBIC,\n        preserve_aspect_ratio=False,\n        antialias=False,\n    )\n\n    # clip overflowing values after interpolation\n    img = tf.clip_by_value(img, 0.0, 1.0)\n\n    return img\n\n\ndef pipeline(filename):\n    # load both low and high res images\n    Y_img = load_img(Y_source + filename)\n    X_img = load_img(X_source + filename)\n\n    return Y_img, X_img\n\ndef PSNR(img, truth, max_val=1):\n    return tf.image.psnr(img, truth, max_val)","metadata":{"executionInfo":{"elapsed":354,"status":"ok","timestamp":1643737814679,"user":{"displayName":"Ashmit Khandelwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKpmFtCMTisPramwd0ZvJzP7b04l1R2eRcTeut0g=s64","userId":"09685033332413984276"},"user_tz":-330},"id":"v6vpBueGOPoE","execution":{"iopub.status.busy":"2022-02-17T18:58:22.913553Z","iopub.execute_input":"2022-02-17T18:58:22.914087Z","iopub.status.idle":"2022-02-17T18:58:22.924775Z","shell.execute_reply.started":"2022-02-17T18:58:22.914043Z","shell.execute_reply":"2022-02-17T18:58:22.92396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define source directories, and load names of image files","metadata":{}},{"cell_type":"code","source":"Y_source = '../input/oxfordpet196/images-upsampled-196/'  # low-res images\nX_source = '../input/oxfordpet196/images-cropped-196/'  # ground truth high-res images\nmodel_save_loc = './srres4-mae'\n\nn_samples = 3000\ninput_size = 196","metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1643735837166,"user":{"displayName":"Ashmit Khandelwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKpmFtCMTisPramwd0ZvJzP7b04l1R2eRcTeut0g=s64","userId":"09685033332413984276"},"user_tz":-330},"id":"si6AlTGWOPoD","execution":{"iopub.status.busy":"2022-02-17T18:58:26.649628Z","iopub.execute_input":"2022-02-17T18:58:26.650024Z","iopub.status.idle":"2022-02-17T18:58:26.655349Z","shell.execute_reply.started":"2022-02-17T18:58:26.64999Z","shell.execute_reply":"2022-02-17T18:58:26.654624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get all the names of img files\nfilenames = os.listdir(Y_source)\nrand_filenames = np.random.choice(filenames, n_samples, replace=False)\nfilenames_dataset = tf.data.Dataset.from_tensor_slices(rand_filenames)","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1643736245856,"user":{"displayName":"Ashmit Khandelwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKpmFtCMTisPramwd0ZvJzP7b04l1R2eRcTeut0g=s64","userId":"09685033332413984276"},"user_tz":-330},"id":"c4OA6Sf6OPoF","execution":{"iopub.status.busy":"2022-02-17T18:58:28.800873Z","iopub.execute_input":"2022-02-17T18:58:28.801572Z","iopub.status.idle":"2022-02-17T18:58:31.333118Z","shell.execute_reply.started":"2022-02-17T18:58:28.801532Z","shell.execute_reply":"2022-02-17T18:58:31.33234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create image dataset using pipeline, shuffle it, split it, and batch it","metadata":{}},{"cell_type":"code","source":"# get dataset of images\ndataset = filenames_dataset.map(pipeline)\ndataset = dataset.shuffle(len(dataset)//4)\n\n# train-val-test split\ndataset_size = len(dataset)\ntrain_size = int(0.85 * dataset_size)\nval_size = int(0.05 * dataset_size)\ntest_size = int(0.1 * dataset_size)\n\ndataset_train = dataset.take(train_size)\ndataset_test = dataset.skip(train_size)\ndataset_val = dataset_test.skip(test_size)\ndataset_test = dataset_test.take(test_size)\n\n# batching\ndataset_train = dataset_train.batch(32)\ndataset_val = dataset_val.batch(32)\ndataset_test = dataset_test.batch(32)\n","metadata":{"executionInfo":{"elapsed":373,"status":"ok","timestamp":1643739246930,"user":{"displayName":"Ashmit Khandelwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKpmFtCMTisPramwd0ZvJzP7b04l1R2eRcTeut0g=s64","userId":"09685033332413984276"},"user_tz":-330},"id":"qAyl2eXJOPoH","execution":{"iopub.status.busy":"2022-02-17T18:58:35.030978Z","iopub.execute_input":"2022-02-17T18:58:35.031881Z","iopub.status.idle":"2022-02-17T18:58:35.300735Z","shell.execute_reply.started":"2022-02-17T18:58:35.031831Z","shell.execute_reply":"2022-02-17T18:58:35.300004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define the model, or import a previously trained one","metadata":{}},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(\n    monitor='val_PSNR', patience=15, mode='max', restore_best_weights=True\n)\n\ncheckpoint = keras.callbacks.ModelCheckpoint(\n    model_save_loc, monitor='val_PSNR', save_best_only=True,\n    mode='max', save_freq='epoch',\n    initial_value_threshold=23.0\n)\n\ncallbacks = [early_stopping, checkpoint]","metadata":{"execution":{"iopub.status.busy":"2022-02-17T18:58:38.445026Z","iopub.execute_input":"2022-02-17T18:58:38.44529Z","iopub.status.idle":"2022-02-17T18:58:39.268465Z","shell.execute_reply.started":"2022-02-17T18:58:38.445259Z","shell.execute_reply":"2022-02-17T18:58:39.267731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import layers\n\n\ndef res_net_block(x, filters, filter_size):\n    x_skip = x\n\n    # Layer 1\n    x = layers.Convolution2D(filters, filter_size, padding='same', activation='relu')(x)\n    # Layer 2\n    x = layers.Convolution2D(filters, filter_size, padding='same')(x)\n    # Add Residue\n    x = layers.Add()([x, x_skip])\n    x = layers.Activation('relu')(x)\n\n    return x\n\n\ndef conv_block(x, filters, filter_size):\n    x = layers.Convolution2D(filters, filter_size, padding='same')(x)\n    x = layers.Activation('relu')(x)\n\n    return x","metadata":{"executionInfo":{"elapsed":521,"status":"ok","timestamp":1643739249929,"user":{"displayName":"Ashmit Khandelwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKpmFtCMTisPramwd0ZvJzP7b04l1R2eRcTeut0g=s64","userId":"09685033332413984276"},"user_tz":-330},"id":"uJw2GZmNOPoJ","outputId":"4d0039db-5cd0-49a5-a61d-acc69e536702","scrolled":true,"execution":{"iopub.status.busy":"2022-02-17T18:58:40.659449Z","iopub.execute_input":"2022-02-17T18:58:40.659728Z","iopub.status.idle":"2022-02-17T18:58:40.672945Z","shell.execute_reply.started":"2022-02-17T18:58:40.659692Z","shell.execute_reply":"2022-02-17T18:58:40.672233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Basic ResNet Model.\n# Requires inputs to already be upsampled to final size, using some kind of interpolation.\n\ninputs = keras.Input(shape=(input_size, input_size, 3))\nx = conv_block(inputs, 16, 9)\n# x = res_net_block(x, 16, 3)\nx = res_net_block(x, 16, 3)\nx = res_net_block(x, 16, 3)\nx = conv_block(x, 32, 3)\n# x = res_net_block(x, 32, 3)\nx = res_net_block(x, 32, 3)\nx = res_net_block(x, 32, 3)\noutputs = layers.Convolution2D(3, 3, activation='linear', padding='same')(x)\n\nmodel = keras.Model(inputs, outputs)\nmodel.compile(optimizer='adam', loss='mae', metrics=[PSNR])","metadata":{"execution":{"iopub.status.busy":"2022-02-17T18:58:43.303097Z","iopub.execute_input":"2022-02-17T18:58:43.303456Z","iopub.status.idle":"2022-02-17T18:58:43.499975Z","shell.execute_reply.started":"2022-02-17T18:58:43.303415Z","shell.execute_reply":"2022-02-17T18:58:43.499074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ResNet model with learnable upsampling.\n# Upsamples image using Transposed Convolution\n\ninputs = keras.Input(shape=(input_size, input_size, 3))\nx = conv_block(inputs, 16, 9)\nx = res_net_block(x, 16, 3)\nx = res_net_block(x, 16, 3)\nx = conv_block(x, 32, 3)\nx = res_net_block(x, 32, 3)\nx = res_net_block(x, 32, 3)\noutputs = layers.Convolution2D(3, 3, activation='linear', padding='same')(x)\n\nmodel = keras.Model(inputs, outputs)\nmodel.compile(optimizer='adam', loss='mae', metrics=[PSNR])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:56:14.181454Z","iopub.status.idle":"2022-02-16T17:56:14.182065Z","shell.execute_reply.started":"2022-02-16T17:56:14.181824Z","shell.execute_reply":"2022-02-16T17:56:14.181849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CNN model with learnable upsampling.\n# Upsamples image using Sub-pixel convolution\n\ninputs = keras.Input(shape=(input_size, input_size, 3))\nx = layers.Conv2DTranspose(8, kernel_size=3, activation='relu')(inputs)  # increase 96x96 -> 98x98\nx = conv_block(x, 16, 9)\n\nx_skip = x\nx = res_net_block(x, 16, 3)\nx = res_net_block(x, 16, 3)\nx = res_net_block(x, 16, 3)\n\nx = conv_block(x, 32, 5)\nx = res_net_block(x, 32, 3)\nx = res_net_block(x, 32, 3)\nx = res_net_block(x, 32, 3)\n\nx = conv_block(x, 16, 5)\nx = layers.Add()([x, x_skip])\nx = conv_block(x, 32, 5)\n\nx = layers.Convolution2D(3 * (2 ** 2), 5, activation='relu', padding='same')(x)  # subpixel conv\nx = tf.nn.depth_to_space(x, 2)\noutputs = layers.Convolution2D(3, 3, activation='linear', padding='same')(x)\n\nmodel = keras.Model(inputs, outputs)\nmodel.compile(optimizer='adam', loss='mae', metrics=[PSNR])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T20:52:08.866162Z","iopub.execute_input":"2022-02-16T20:52:08.866418Z","iopub.status.idle":"2022-02-16T20:52:09.103152Z","shell.execute_reply.started":"2022-02-16T20:52:08.866383Z","shell.execute_reply":"2022-02-16T20:52:09.102404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load previously trained model to continue training\nmodel = keras.models.load_model(model_save_loc, custom_objects={'res_net_block': res_net_block, 'PSNR': PSNR})","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-02-16T17:56:14.184986Z","iopub.status.idle":"2022-02-16T17:56:14.185592Z","shell.execute_reply.started":"2022-02-16T17:56:14.185354Z","shell.execute_reply":"2022-02-16T17:56:14.185379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\nhists = []","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-02-17T18:58:46.869366Z","iopub.execute_input":"2022-02-17T18:58:46.869639Z","iopub.status.idle":"2022-02-17T18:58:46.884864Z","shell.execute_reply.started":"2022-02-17T18:58:46.869607Z","shell.execute_reply":"2022-02-17T18:58:46.884043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train the model, view PSNR performance trend, and run some test examples ","metadata":{}},{"cell_type":"code","source":"hist = model.fit(dataset_train, epochs=100,callbacks=callbacks, validation_data=dataset_val)\nhists.append(hist)","metadata":{"executionInfo":{"elapsed":182353,"status":"ok","timestamp":1643739435235,"user":{"displayName":"Ashmit Khandelwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKpmFtCMTisPramwd0ZvJzP7b04l1R2eRcTeut0g=s64","userId":"09685033332413984276"},"user_tz":-330},"id":"qVHvDPW9OPoJ","outputId":"db4dda0d-3585-4571-aa23-c127f735f54a","execution":{"iopub.status.busy":"2022-02-17T18:58:51.364112Z","iopub.execute_input":"2022-02-17T18:58:51.364367Z","iopub.status.idle":"2022-02-17T19:10:33.867888Z","shell.execute_reply.started":"2022-02-17T18:58:51.364337Z","shell.execute_reply":"2022-02-17T19:10:33.867122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_train, hist_val = [], []\n\n# join together PSNR data from all epochs\nfor hist in hists:\n    hist_train += hist.history['PSNR']\n    hist_val += hist.history['val_PSNR']\n\n# and display them\nplt.plot(hist_train, label='train PSNR')\nplt.plot(hist_val, label='val PSNR')\n\nplt.legend()\nplt.show()","metadata":{"executionInfo":{"elapsed":472,"status":"ok","timestamp":1643739802932,"user":{"displayName":"Ashmit Khandelwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKpmFtCMTisPramwd0ZvJzP7b04l1R2eRcTeut0g=s64","userId":"09685033332413984276"},"user_tz":-330},"id":"xY0RH33Hg--Q","outputId":"d0c00ece-afa9-4fba-8ca6-5a9b2df059f1","execution":{"iopub.status.busy":"2022-02-17T19:10:41.550161Z","iopub.execute_input":"2022-02-17T19:10:41.550429Z","iopub.status.idle":"2022-02-17T19:10:56.989154Z","shell.execute_reply.started":"2022-02-17T19:10:41.550399Z","shell.execute_reply":"2022-02-17T19:10:56.988474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.ops.numpy_ops import np_config\n\nnp_config.enable_numpy_behavior()\n\ndef show(img, title=''):\n    plt.axis('off')\n    plt.imshow(img)\n    plt.title(title)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:56:14.192088Z","iopub.status.idle":"2022-02-16T17:56:14.192694Z","shell.execute_reply.started":"2022-02-16T17:56:14.192472Z","shell.execute_reply":"2022-02-16T17:56:14.192496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See the SRResNet's performace (Bicubic vs Model vs Ground Truth) on a few test examples\nfor Y, X in dataset_test.take(5):\n    pred_mat = model.predict(Y)[0]\n    Y = Y[0]\n    X = X[0]\n    \n    show(Y.numpy(), title=f'Bicubic | PSNR:{round(PSNR(Y, X).numpy(),2)} dB')\n    show(pred_mat, title=f'SRResNet | PSNR:{round(PSNR(pred_mat, X).numpy(),2)} dB')\n    show(X.numpy(), title='Ground Truth')","metadata":{"executionInfo":{"elapsed":8208,"status":"ok","timestamp":1643739195164,"user":{"displayName":"Ashmit Khandelwal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiKpmFtCMTisPramwd0ZvJzP7b04l1R2eRcTeut0g=s64","userId":"09685033332413984276"},"user_tz":-330},"id":"AMN4nZ3hPHmC","outputId":"b373030d-cb5d-41ab-c960-be19871dc44b","execution":{"iopub.status.busy":"2022-02-16T17:56:14.193824Z","iopub.status.idle":"2022-02-16T17:56:14.194445Z","shell.execute_reply.started":"2022-02-16T17:56:14.1942Z","shell.execute_reply":"2022-02-16T17:56:14.194225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See the SRResNet-SubPix' performace (Bicubic vs Model vs Ground Truth) on a few test examples\nfor Y, X in dataset_test.take(5):\n    pred_mat = model.predict(Y)[0]\n    Y = Y[0]\n    X = X[0]\n    \n    # upsample Y using bicupic interpolation \n    Y = upsample(Y, 196)\n    \n    show(Y.numpy(), title=f'Bicubic | PSNR:{round(PSNR(Y, X).numpy(),2)} dB')\n    show(pred_mat, title=f'SRResNet-SubPix | PSNR:{round(PSNR(pred_mat, X).numpy(),2)} dB')\n    show(X.numpy(), title='Ground Truth')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:56:14.19561Z","iopub.status.idle":"2022-02-16T17:56:14.196219Z","shell.execute_reply.started":"2022-02-16T17:56:14.195991Z","shell.execute_reply":"2022-02-16T17:56:14.196017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get test accuracy\n_, acc = model.evaluate(dataset_test, verbose=0)\nprint(f'Test PSNR: {round(acc,2)} dB')","metadata":{"execution":{"iopub.status.busy":"2022-02-17T19:11:58.989075Z","iopub.execute_input":"2022-02-17T19:11:58.989607Z","iopub.status.idle":"2022-02-17T19:12:03.020685Z","shell.execute_reply.started":"2022-02-17T19:11:58.989569Z","shell.execute_reply":"2022-02-17T19:12:03.019921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save the model","metadata":{}},{"cell_type":"code","source":"model.save(model_save_loc)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T21:21:10.31579Z","iopub.execute_input":"2022-02-16T21:21:10.316087Z","iopub.status.idle":"2022-02-16T21:21:14.430255Z","shell.execute_reply.started":"2022-02-16T21:21:10.316054Z","shell.execute_reply":"2022-02-16T21:21:14.428304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load previously trained model to continue training\nmodel_t = keras.models.load_model('./srres6-subpix', {'PSNR': PSNR})\n# get test accuracy\n_, acc = model_t.evaluate(dataset_test, verbose=0)\nprint(f'Test PSNR: {round(acc,2)} dB')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T17:56:14.200884Z","iopub.status.idle":"2022-02-16T17:56:14.201503Z","shell.execute_reply.started":"2022-02-16T17:56:14.201259Z","shell.execute_reply":"2022-02-16T17:56:14.201284Z"},"trusted":true},"execution_count":null,"outputs":[]}]}